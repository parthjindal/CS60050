{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT DEPENDENCIES AND LIBRARY METHODS AND CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from models.MLP import MLP0, MLP1, MLP2\n",
    "from util import create_dataloaders, seed_everything, \\\n",
    "    train, test, preprocess_dataset, MultiTransforms, \\\n",
    "    TransformPCA, SatelliteDataset\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "IN_DIMS = 36\n",
    "OUT_DIMS = 6 # label 6 has zero items so 6 classes only\n",
    "DEVICE = \"cuda:0\"\n",
    "ROOT_DIR = \"dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET CREATION, PREPROCESSING AND DATALOADERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SatelliteDataset(\"./dataset\", train=True)\n",
    "test_dataset = SatelliteDataset(\"./dataset\", train=False)\n",
    "\n",
    "# mean center and normalize\n",
    "transform, target_transform = preprocess_dataset(train_dataset)\n",
    "\n",
    "train_dataset.transform = transform\n",
    "train_dataset.target_transform = target_transform\n",
    "\n",
    "test_dataset.transform = transform\n",
    "test_dataset.target_transform = target_transform\n",
    "\n",
    "# create dataloaders of batch size 1\n",
    "train_loader, test_loader = create_dataloaders(train_dataset, test_dataset,\n",
    "                                               shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model: nn.Module,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    args,\n",
    "):\n",
    "    train_loss = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    test_loss = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    early_stop_count = 0\n",
    "    early_stop_patience = 5\n",
    "    early_stop_tol = 5e-3\n",
    "\n",
    "    best_train_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    progress_bar = tqdm(range(args.max_epochs),\n",
    "                        desc=\"Epochs\", disable=~args.verbose)\n",
    "\n",
    "    for i in progress_bar:\n",
    "        losses, train_acc = train(model, train_loader,\n",
    "                                  lr=args.lr, device=args.device)\n",
    "        loss = np.mean(losses)\n",
    "        train_loss.append(loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        best_train_acc = max(best_train_acc, train_acc)\n",
    "\n",
    "        test_acc = 0\n",
    "        progress_dict = {\"Loss\": loss, \"Train Acc\": train_acc}\n",
    "\n",
    "        if i % args.test_freq == 0:\n",
    "            results = test(model, test_loader,\n",
    "                           device=args.device, metrics=[\"Accuracy\", \"Loss\"])\n",
    "            test_acc = results[\"Accuracy\"]\n",
    "            test_accuracies.append(test_acc)\n",
    "            test_loss.append(results[\"Loss\"])\n",
    "            progress_dict[\"Test Accuracy\"] = test_acc\n",
    "            best_test_acc = max(best_test_acc, test_acc)\n",
    "\n",
    "        if i % args.log_freq == 0 and args.verbose:\n",
    "            progress_bar.set_postfix(progress_dict)\n",
    "\n",
    "        if len(train_loss) > 1 and abs(loss-train_loss[-2]) < early_stop_tol:\n",
    "            early_stop_count += 1\n",
    "            if (early_stop_count >= early_stop_patience):\n",
    "                print(f\"Early stopping after {i} epochs.\")\n",
    "                break\n",
    "        else:\n",
    "            early_stop_count = 0\n",
    "\n",
    "    if args.plot is True:\n",
    "        # plot loss and accuracy in same plot\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax[0].plot(train_loss, label=\"train\")\n",
    "        ax[0].plot(test_loss, label=\"test\")\n",
    "        ax[0].set_xlabel(\"Epoch\")\n",
    "        ax[0].set_ylabel(\"Loss\")\n",
    "\n",
    "        ax[1].plot(train_accuracies, label=\"train\")\n",
    "        ax[1].plot(test_accuracies, label=\"test\")\n",
    "        ax[1].set_xlabel(\"Epoch\")\n",
    "        ax[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "        ax[0].legend()\n",
    "        ax[1].legend()\n",
    "        plt.show()\n",
    "\n",
    "    return best_train_acc, best_test_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for model architecture:\n",
    "1. 0 hidden layers\n",
    "2. sigmoid activation function\n",
    "3. input_dim = 36, output_dim = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP1_1 with lr 0.01 test accuracy: 0.6758379189594798\n",
      "MLP1_1 with lr 0.001 test accuracy: 0.5962981490745373\n",
      "MLP1_1 with lr 0.0001 test accuracy: 0.5852926463231616\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    # \"MLP0\": MLP0(IN_DIMS, OUT_DIMS),\n",
    "    # \"MLP1_0\": MLP1(IN_DIMS, OUT_DIMS, 2),\n",
    "    \"MLP1_1\": MLP1(IN_DIMS, OUT_DIMS, 6),\n",
    "    # \"MLP2_0\": MLP2(IN_DIMS, OUT_DIMS, 2, 3),\n",
    "    # \"MLP2_1\": MLP2(IN_DIMS, OUT_DIMS, 3, 2),\n",
    "}\n",
    "\n",
    "results = dict()\n",
    "lrs = [1e-2, 1e-3, 1e-4,]\n",
    "for name, model in models.items():\n",
    "    model = model.to(DEVICE)\n",
    "    results[name] = []\n",
    "    for lr in lrs:\n",
    "        args = argparse.Namespace(max_epochs=5, lr=lr, device=DEVICE,\n",
    "                                  verbose=True, log_freq=1, test_freq=1, plot=False)\n",
    "        train_acc,  test_acc = fit(model, train_loader, test_loader, args)\n",
    "        results[name].append((train_acc, test_acc))\n",
    "        print(f\"{name} with lr {lr} test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(train_dataset.data)\n",
    "pca_transform = TransformPCA(pca)\n",
    "transforms = MultiTransforms([mtransform, pca_transform])\n",
    "\n",
    "train_dataset.transform = transforms\n",
    "train_dataset.target_transform = mtarget_transform"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a529b7424b79f2c540a1cbf977a80ecba331b72ab360de384ef569b2ff0755e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('RL': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
